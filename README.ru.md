# Snake-With-Q-Learning (RU)

Интерактивная игра «Змейка» с эволюционным Q‑обучением. Рендер через `pixels`/`winit` с полупрозрачной панелью управления. Можно играть вручную или наблюдать, как популяция агентов обучается играть с помощью Q‑learning и эволюционных стратегий.

[English version](./README.md)

## Возможности

- Классическая «Змейка» на фиксированной сетке (окно 800×600, ячейки по 20 пикселей).
- Плавный пиксельный рендер с шахматным фоном и «глазами» у головы змеи.
- Экранная панель: счёт, длина, скорость, статус эволюции, график лучших результатов по эпохам, быстрые кнопки.
- Q‑агент с компактным представлением состояния (20 бит) и тремя действиями: повернуть влево, прямо, вправо.
- Эволюционный тренер: параллельный запуск нескольких агентов, элитизм, мутации, адаптивные рестарты при стагнации.
- Автосохранение и автозагрузка лучшего агента (чемпиона) в/из `snake_agent.json`.

## Управление

- Движение: стрелки или WASD
- Пауза/продолжить: P
- Перезапуск: R (когда игра окончена или кнопкой на панели)
- Эволюция (вкл/выкл): E
- Скорость:
  - Ручная игра: `+`/`-` изменяют длительность тика
  - Эволюция: `+` удваивает и `-` делит на 2 шаги/кадр (до 100 000)
- Сохранить лучшего агента: S
- Скрыть/показать панель: H
- Выход: Esc или закрыть окно
- Мышь: клики по кнопкам панели (Pause/Resume, Speed+, Restart, Save, Hide/Show)

## Сборка и запуск

Требуется:
- Установленный Rust (stable)
- Windows (проверено), также должно работать на других платформах, поддерживаемых `pixels`/`winit`.

Запуск (debug):

```powershell
cargo run
```

Запуск (оптимизированный):

```powershell
cargo run --release
```

При старте приложение пытается загрузить `snake_agent.json`. Если файл найден, эволюция запускается автоматически, используя загруженного агента как семя.

## Как устроено обучение

### Кодирование состояния (зрение + контекст)
Агент «видит» 8 критически важных клеток вокруг головы в относительных координатах (зона 3×3 впереди). Каждая клетка кодируется двумя битами:
- 00 — пусто
- 01 — опасность (стена/тело)
- 10 — яблоко
- 11 — не используется

Это 16 бит. Дополнительно:
- 2 бита: относительное направление до яблока (влево/прямо/вправо)
- 2 бита: категория манхэттенского расстояния до яблока (4 корзины)

Итого: 20 бит (~1 млн состояний).

### Действия
Три дискретных действия относительно текущего направления:
- 0 — повернуть влево
- 1 — прямо
- 2 — повернуть вправо

### Награды
- +10.0 за яблоко, чуть выше с увеличением длины
- −10.0 за смерть
- Небольшой штраф за шаг (−0.005)
- Shaping: небольшой бонус при приближении к яблоку и небольшой штраф при удалении

### Параметры QAgent
- Эпсилон‑жадная политика с затуханием (`epsilon`, `min_epsilon`, `decay`)
- Скорость обучения `alpha`, дисконт‑фактор `gamma`
- Счётчики `steps` и `episodes` для метрик

### Эволюционный тренер
- Популяция агентов (по умолчанию 10), каждый играет в своей копии игры
- В конце эпохи — воспроизводство: элитизм + мутации; несколько сценариев рестартов при долгой стагнации
- Глобальный «чемпион» (лучший за всё время), автосохранение при улучшении результата
- Визуализация: каждому агенту присваивается уникальный цвет

## Структура кода

- `src/main.rs` — основной бинарник со всей логикой игры/рендера, Q‑обучением и тренером.
- `snake_agent.json` — файл с сохранённым чемпионом (создаётся при сохранении).
- `src/game.rs`, `src/draw.rs`, `src/pos.rs` — ранее/альтернативная TUI‑версия, не используется в текущей сборке.

## Советы

- Чтобы начать обучение с нуля, удалите `snake_agent.json` или нажмите E, чтобы включить эволюцию.
- На очень высоких скоростях кадры частично пропускаются, а рисование может быть отключено для максимальной производительности.
- Размеры сетки/клеток задаются константами вверху `main.rs` и легко настраиваются.

## Лицензия

Лицензия не указана. Добавьте её, если планируете распространение.
