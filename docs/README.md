# Документация проекта Snake-With-Q-Learning

Этот раздел описывает устройство кода, архитектуру, зависимости и способы сборки/запуска на Windows. Проект реализован на Rust и представляет игру «Змейка» с возможностью эволюционного Q‑обучения (табличный агент) и опциональными режимами DQN (Candle) и NPU (ONNX Runtime + DirectML).

- Для краткого обзора возможностей и управления см. файлы README.md и README.ru.md в корне репозитория.
- Ниже: подробная документация по модулям `src/`, протоколам данных и нюансам сборки.

Содержание:
- 1. Архитектура и модули
- 2. Игровая логика (`Game`)
- 3. Агент Q‑learning (`QAgent`) и эволюционный тренер (`EvoTrainer`)
- 4. Ключевая функция `state_key`
- 5. Рендеринг (CPU и GPU)
- 6. Режим DQN (Candle)
- 7. Режим NPU (ONNX Runtime, DirectML)
- 8. Горячие клавиши и панель управления
- 9. Сборка и запуск
- 10. Тесты/проверки качества и типичные проблемы

## 1. Архитектура и модули

- `src/main.rs` — основной бинарник. Содержит:
  - Игровую модель `Game` (позиции, змейка, яблоко, шаг симуляции, отрисовка на CPU).
  - Простого табличного агента `QAgent` и эволюционный тренер `EvoTrainer`.
  - Ввод/обработку событий через `winit_input_helper` и цикл отрисовки.
  - Панель управления (HUD) и график результатов по эпохам.
  - Включаемые по фичам режимы DQN и NPU.
- `src/dqn.rs` — включается с фичей `dqn-gpu`. DQN на библиотеке Candle (CPU/CUDA), с буфером повторов, обучением и сохранением веса в `.safetensors`.
- `src/gpu_render.rs` — включается с фичей `gpu-render`. Рендеринг сцены на `wgpu` (шахматный фон и инстансные прямоугольники для сегментов змеи и яблока). Шейдеры в `grid.wgsl` и `instanced.wgsl`.
- `src/npu.rs` — включается на Windows с фичей `npu-directml`. Инференс ONNX‑модели через ONNX Runtime/DirectML.
- `src/gpu_nn.rs` — экспериментальная заготовка (фича `gpu-nn`) отключена компиляционной ошибкой преднамеренно.

Основные зависимости:
- Рендер (CPU): `pixels`
- Окно/ввод: `winit`, `winit_input_helper`
- Параллелизм: `rayon`
- Быстрый хеш: `ahash`
- Графика (GPU, опционально): `wgpu`
- DQN (опционально): `candle-core`, `candle-nn`
- NPU/DirectML (опционально): `ort`, `ndarray`

## 2. Игровая логика (`Game`)

Контейнеры:
- `snake: VecDeque<Pos>` и `snake_set: HashSet<Pos>` для быстрых проверок самопересечения.
- `dir: Dir` — направление движения, запрет разворота на 180° в `change_dir`.
- `apple: Pos`, `score: usize`, `alive: bool`, `paused: bool`.
- `wrap_world: bool` — включение тороидального мира (обёртка по краям) или «твёрдых» стен.

Ключевые методы:
- `new()`/`new_with_wrap(bool)`: инициализация змейки, размещение яблока.
- `place_apple()`: выбор случайной свободной клетки.
- `update()`: один тик — смещение головы, проверка стен (с учётом wrap), самопересечений, съедание яблока, рост/сдвиг хвоста.
- `draw(frame)` и вспомогательные функции отрисовки для режима `pixels`.

## 3. Агент Q‑learning (`QAgent`) и эволюционный тренер (`EvoTrainer`)

`QAgent` хранит Q‑таблицу `AHashMap<u32, [f32;3]>` по компактному ключу состояния (см. ниже), использует ε‑жадную политику:
- `select_action(state, rng) -> usize`
- `learn(s, a, r, ns, done)` — обновление по формуле Q‑обучения
- Параметры: `epsilon, min_epsilon, decay, alpha, gamma`

`EvoTrainer` управляет популяцией агентов и параллельными играми:
- Поля: `pop`, `games`, `scores`, `epoch`, `best_score`, `champion` и т.д.
- `reproduce(rng)` — отбор/элитизм, мутации, «перезапуски при стагнации» с несколькими стратегиями. Лидер‑протекция не даёт уникальному лидеру завершить эпоху по лимиту шагов.
- `set_wrap_world(bool)` — переключение режима стен/обёртки (используется DQN‑режимом).

Отображение агентов цветом: генерация разнообразной палитры `generate_population_colors` + лёгкая мутация цвета у потомков.

## 4. Ключевая функция `state_key`

Кодирует состояние в 20 бит:
- 16 бит — «визуальный» обзор 8 соседних ячеек вокруг головы в локальных координатах движения: по 2 бита на клетку (00 пусто, 01 опасность — стена или тело, 10 яблоко, 11 не используется).
- 2 бита — относительное направление до яблока (влево/прямо/вправо; грубо квантуется).
- 2 бита — «корзина» манхэттенского расстояния до яблока.

Такой ключ хорошо подходит для компактной Q‑таблицы и быстрых проверок/обучения.

## 5. Рендеринг

- CPU‑путь (по умолчанию): `pixels`. Рисуется фон в «шахматном» стиле, яблоко и сегменты змейки, у головы — «глаза».
- HUD/панель: полупрозрачная панель слева, кнопки, график лучших результатов по эпохам, счётчики FPS.
- GPU‑путь (фича `gpu-render`): сцена рисуется через `wgpu` двумя пайплайнами: фон (full‑screen) и инстансные «клетки». Данные инстансов собираются в `main.rs`.

## 6. Режим DQN (Candle)

Включается фичей `dqn-gpu`. Модуль `src/dqn.rs`:
- Сеть: embedding + MLP, выход из 3 действий. Обучение MSE по таргету `r + γ max_a' Q(ns,a')` с маской эпизодных завершений.
- Буфер повторов `Replay` и простая стратегия сэмплирования (первые `batch` — можно улучшить).
- Устройство по умолчанию CPU, при `dqn-gpu-cuda` пытается использовать CUDA.
- Сохранение/загрузка весов в `.safetensors`.
- В `main.rs` DQN включается клавишей J. При активном DQN тренер переключает мир на «твёрдые» стены для более стабильного обучения.

## 7. Режим NPU (DirectML, ONNX)

Включается фичей `npu-directml` на Windows. Модуль `src/npu.rs`:
- Загружает `snake_dqn.onnx` (путь ищется в переменной окружения `SNAKE_NPU_ONNX` или в стандартных каталогах рядом с бинарником).
- Выполняет инференс: вход — индекс состояния (как категория), выход — логиты по 3 действиям; выбирается argmax.
- Используется только для выбора действий в режиме Evolution (клавиша K переключает режим).

## 8. Горячие клавиши и панель управления

- Движение: стрелки или WASD
- Пауза: P
- Рестарт: R
- Эволюция: E
- Скорость: `+`/`-` (вручную — изменяет тик; в Evolution — множитель шагов/кадр)
- Панель: H (показ/скрытие)
- Ultra‑fast: U (резко повышает бюджет шагов, может отключить отрисовку)
- Показ только лучшего агента: B
- DQN: J (требует фичу `dqn-gpu`)
- NPU: K (требует Windows + фичу `npu-directml` + модель ONNX)
- GPU‑бюджет: G (меняет только бюджет шагов; не включает обучение на GPU)

## 9. Сборка и запуск

Базовая сборка (Windows PowerShell):

```powershell
cargo run
```

Оптимизированный запуск:

```powershell
cargo run --release
```

С фичами:
- GPU‑рендеринг:
  ```powershell
  cargo run --features gpu-render
  ```
- DQN на CPU:
  ```powershell
  cargo run --features dqn-gpu
  ```
- DQN с CUDA (нужны CUDA Toolkit и корректная установка candle-core с фичей cuda):
  ```powershell
  cargo run --features "dqn-gpu dqn-gpu-cuda"
  ```
- NPU (ONNX Runtime + DirectML), только Windows:
  ```powershell
  $env:SNAKE_NPU_ONNX = "C:\\path\\to\\snake_dqn.onnx"; cargo run --features npu-directml
  ```

Примечания:
- Фича `gpu-nn` отключена и вызывает компиляционную ошибку преднамеренно.
- Если используете `gpu-render`, убедитесь в наличии совместимого адаптера `wgpu`.
- Для CUDA потребуются драйверы NVIDIA и установленный NVCC.

## 10. Качество кода и типичные проблемы

- Быстрая проверка сборки: `cargo build` — должна проходить без предупреждений (на текущей ветке предупреждения устранены).
- Рекомендуется запустить `cargo clippy` (если установлен) для дополнительных подсказок.
- Типичные проблемы:
  - Нет модели ONNX при включении NPU: проверьте `SNAKE_NPU_ONNX` или расположите файл в поддерживаемых каталогах.
  - DQN на CUDA: ошибки инициализации устройства — проверьте наличие CUDA Runtime/Toolkit и совместимость версии.
  - Низкий FPS при высокой скорости эволюции — используйте U или B для уменьшения нагрузки на отрисовку.

Обратная связь и улучшения приветствуются! Открывайте issues/PR.
